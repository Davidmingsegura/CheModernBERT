{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(embeddings_smiles, embeddings_text, title, save_path):\n",
    "    pca = PCA(n_components=2)\n",
    "    smiles_pca = pca.fit_transform(embeddings_smiles)\n",
    "    text_pca = pca.transform(embeddings_text)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(smiles_pca[:, 0], smiles_pca[:, 1], label=\"SMILES\", alpha=0.7)\n",
    "    plt.scatter(text_pca[:, 0], text_pca[:, 1], label=\"Text\", alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.title(title, size=18)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"PCA plot saved at: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def recall_at_k(smiles_embeddings, text_embeddings, k=5):\n",
    "    cosine_sim = np.dot(smiles_embeddings, text_embeddings.T)\n",
    "    top_k_indices = np.argsort(cosine_sim, axis=1)[:, -k:]\n",
    "    ground_truth_indices = np.arange(len(smiles_embeddings)).reshape(-1, 1)\n",
    "    recall_k = np.mean(np.any(top_k_indices == ground_truth_indices, axis=1))\n",
    "    return recall_k\n",
    "\n",
    "def mean_reciprocal_rank(smiles_embeddings, text_embeddings):\n",
    "    cosine_sim = np.dot(smiles_embeddings, text_embeddings.T)\n",
    "    sorted_indices = np.argsort(-cosine_sim, axis=1)\n",
    "    ranks = np.where(sorted_indices == np.arange(len(smiles_embeddings)).reshape(-1, 1))[1] + 1\n",
    "    mrr = np.mean(1 / ranks)\n",
    "    return mrr\n",
    "\n",
    "def retrieval_accuracy(smiles_embeddings, text_embeddings):\n",
    "    cosine_sim = np.dot(smiles_embeddings, text_embeddings.T)\n",
    "    retrieved_indices = np.argmax(cosine_sim, axis=1)\n",
    "    ground_truth_indices = np.arange(len(smiles_embeddings))\n",
    "    return accuracy_score(ground_truth_indices, retrieved_indices)\n",
    "\n",
    "def extract_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    smiles_embeddings = []\n",
    "    text_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            smiles_input = batch['title_input_ids'].to(device)\n",
    "            text_input = batch['abstract_input_ids'].to(device)\n",
    "            smiles_mask = batch['title_attention_mask'].to(device)\n",
    "            text_mask = batch['abstract_attention_mask'].to(device)\n",
    "            z_smiles = model(smiles_input, attention_mask=smiles_mask).last_hidden_state[:, 0, :]\n",
    "            z_text = model(text_input, attention_mask=text_mask).last_hidden_state[:, 0, :]\n",
    "            z_smiles = F.normalize(z_smiles, p=2, dim=-1).cpu().numpy()\n",
    "            z_text = F.normalize(z_text, p=2, dim=-1).cpu().numpy()\n",
    "            smiles_embeddings.append(z_smiles)\n",
    "            text_embeddings.append(z_text)\n",
    "    smiles_embeddings = np.vstack(smiles_embeddings)\n",
    "    text_embeddings = np.vstack(text_embeddings)\n",
    "    return smiles_embeddings, text_embeddings\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            smiles_input = batch['title_input_ids'].to(device)\n",
    "            text_input = batch['abstract_input_ids'].to(device)\n",
    "            smiles_mask = batch['title_attention_mask'].to(device)\n",
    "            text_mask = batch['abstract_attention_mask'].to(device)\n",
    "            z_smiles = model(smiles_input, attention_mask=smiles_mask).last_hidden_state[:, 0, :]\n",
    "            z_text = model(text_input, attention_mask=text_mask).last_hidden_state[:, 0, :]\n",
    "            z_smiles = F.normalize(z_smiles, p=2, dim=-1)\n",
    "            z_text = F.normalize(z_text, p=2, dim=-1)\n",
    "            loss = contrastive_loss(z_smiles, z_text)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TitleAbstractContrastiveDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = self.data.iloc[idx][\"title\"]\n",
    "        abstract = self.data.iloc[idx][\"text\"]\n",
    "        \n",
    "        title_encoding = self.tokenizer(\n",
    "            title,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        abstract_encoding = self.tokenizer(\n",
    "            abstract,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"title_input_ids\": title_encoding[\"input_ids\"].squeeze(0),\n",
    "            \"title_attention_mask\": title_encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"abstract_input_ids\": abstract_encoding[\"input_ids\"].squeeze(0),\n",
    "            \"abstract_attention_mask\": abstract_encoding[\"attention_mask\"].squeeze(0)\n",
    "        }\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_paths = {\n",
    "#  'bert-base-uncased': 'bert-base-uncased',\n",
    "#  'ChemBERTa-MLM': 'DeepChem/ChemBERTa-77M-MLM',\n",
    "#  'ChemBERTa-MTR': 'DeepChem/ChemBERTa-77M-MTR',\n",
    "#  \"MoLFormer\":'ibm-research/MoLFormer-XL-both-10pct',\n",
    "#  'SciBERT uncased': 'allenai/scibert_scivocab_uncased',\n",
    "#  'SciBERT cased': 'allenai/scibert_scivocab_cased',\n",
    "#  'ModernBERT': 'answerdotai/ModernBERT-base',\n",
    "#  'ModernBERT base 500k': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-1n4g-no-tags',\n",
    "#  'ModernBERT base Procedures 500k': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-500k-notags',\n",
    "#  'ModernBERT base Procedures 1M5': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-1M5-notags',\n",
    "#  'ModernBERT base Procedures 1M5 10 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-10-epochs-notags',\n",
    "#  'ModernBERT base Procedures 1M5 20 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-20-epochs-notags',\n",
    "#  'ModernBERT base Procedures 1M5 30 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-30-epochs-notags',\n",
    "#  'ModernBERT base Procedures 1M5 40 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-40-epochs-notags',\n",
    "#  'ModernBERT base Procedures 1M5 50 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-50-epochs-notags',\n",
    "#  'ModernBERT base Procedures 1M5 60 epochs': '/home/david/modernbert_chemistry/fineweb/fine-web-modernbert-base-8192-multi-tok-new-procedure-60-epochs-notags',\n",
    "}\n",
    "\n",
    "train_dataset = TitleAbstractContrastiveDataset(train_df, None)\n",
    "val_dataset   = TitleAbstractContrastiveDataset(val_df, None)\n",
    "test_dataset  = TitleAbstractContrastiveDataset(test_df, None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "temperature_values = [0.1] \n",
    "results = [] \n",
    "\n",
    "for model_name, model_path in model_paths.items():\n",
    "    print(f\"\\n===== Running experiments for model: {model_name} =====\")\n",
    "    \n",
    "    for temp in temperature_values:\n",
    "        print(f\"\\nðŸ”¹ Training {model_name} with temperature Ï„ = {temp}\")\n",
    "\n",
    "        def contrastive_loss(z1, z2, temperature=0.1):\n",
    "            z1 = F.normalize(z1, p=2, dim=-1)\n",
    "            z2 = F.normalize(z2, p=2, dim=-1)\n",
    "\n",
    "            sim_matrix = torch.matmul(z1, z2.T) / temperature\n",
    "            sim_matrix = sim_matrix.clamp(-10.0, 10.0)\n",
    "            sim_matrix = sim_matrix.float()\n",
    "            labels = torch.arange(z1.size(0), device=sim_matrix.device)\n",
    "            return F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        train_dataset.tokenizer = tokenizer\n",
    "        val_dataset.tokenizer = tokenizer\n",
    "        test_dataset.tokenizer = tokenizer\n",
    "\n",
    "        model = AutoModel.from_pretrained(model_path, output_hidden_states=True)\n",
    "        model.to(device)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "        scaler = GradScaler()\n",
    "        accumulation_steps = 4\n",
    "\n",
    "        for epoch in range(5):\n",
    "            total_train_loss = 0\n",
    "            model.train()\n",
    "            print(f\"\\nEpoch {epoch+1} [Training]:\")\n",
    "            train_progress = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} [Training]\")\n",
    "\n",
    "            for step, batch in enumerate(train_progress):\n",
    "                title_input = batch[\"title_input_ids\"].to(device)\n",
    "                abstract_input = batch[\"abstract_input_ids\"].to(device)\n",
    "                title_mask = batch[\"title_attention_mask\"].to(device)\n",
    "                abstract_mask = batch[\"abstract_attention_mask\"].to(device)\n",
    "                \n",
    "                with autocast():\n",
    "                    z_title    = model(\n",
    "                                    title_input,\n",
    "                                    attention_mask=title_mask\n",
    "                                ).last_hidden_state[:, 0, :]   \n",
    "                    z_abstract = model(\n",
    "                                    abstract_input,\n",
    "                                    attention_mask=abstract_mask\n",
    "                                ).last_hidden_state[:, 0, :]\n",
    "                    loss = contrastive_loss(z_title, z_abstract) / accumulation_steps\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                total_train_loss += loss.item() * accumulation_steps\n",
    "                if (step + 1) % accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                train_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            print(f\"\\nEpoch {epoch+1} [Training] Average Loss: {avg_train_loss:.4f}\")\n",
    "            avg_val_loss = evaluate(model, val_dataloader, device)\n",
    "            print(f\"Epoch {epoch+1} [Validation] Loss: {avg_val_loss:.4f}\")\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        test_smiles, test_text = extract_embeddings(model, test_dataloader, device)\n",
    "        top1_acc = retrieval_accuracy(test_smiles, test_text)\n",
    "        mrr_score = mean_reciprocal_rank(test_smiles, test_text)\n",
    "        recall5_score = recall_at_k(test_smiles, test_text, k=5)\n",
    "\n",
    "        exp_result = {\n",
    "            \"Model\": model_name,\n",
    "            \"Temperature\": temp,\n",
    "            \"Top-1 Accuracy\": top1_acc,\n",
    "            \"MRR\": mrr_score,\n",
    "            \"Recall@5\": recall5_score\n",
    "        }\n",
    "        results.append(exp_result)\n",
    "        \n",
    "        save_path_1 = f\"/home/david/modernbert_chemistry/fineweb/results_allmodels/{model_name}_contrastive-pca-_title_text_1-temp-{temp:.2f}.png\"\n",
    "        plot_pca(test_smiles, test_text, f\"PCA Plot for {model_name} at Temp {temp}\", save_path_1)\n",
    "\n",
    "\n",
    "        del model, test_smiles, test_text\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "bar_width = 2.8\n",
    "spacing_factor = 10\n",
    "\n",
    "indices = np.arange(len(results_df)) * spacing_factor\n",
    "cmap = plt.colormaps[\"plasma_r\"]\n",
    "\n",
    "bars1 = plt.bar(indices, results_df[\"Top-1 Accuracy\"], bar_width, label=\"Top-1 Accuracy\", color=cmap(0.2))\n",
    "bars2 = plt.bar(indices + bar_width, results_df[\"MRR\"], bar_width, label=\"MRR\", color=cmap(0.5))\n",
    "bars3 = plt.bar(indices + 2 * bar_width, results_df[\"Recall@5\"], bar_width, label=\"Recall@5\", color=cmap(0.8))\n",
    "\n",
    "plt.xlabel(\"Experiment Index\", size=15)\n",
    "plt.ylabel(\"Score\", size=15)\n",
    "plt.title(\"Contrastive Retrieval Performance\", size=18)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(indices + bar_width, results_df[\"Model\"], rotation=45, ha='right', size=14)\n",
    "\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height,\n",
    "            f'{height*100:.1f}%',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "\n",
    "plt.legend(\n",
    "    fontsize=14,\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.05, 1.0),\n",
    "    borderaxespad=0\n",
    ")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
